# ğŸš• NYC Yellow Taxi â€“ ELT Pipeline sur GCP (BigQuery, GCS, Airflow, SQL & Analytics)

## ğŸ“Œ PrÃ©sentation du projet
Ce projet met en Å“uvre un **pipeline ELT complet sur Google Cloud Platform (GCP)** Ã  partir des donnÃ©es publiques des **NYC Yellow Taxi Trips**.

Lâ€™objectif est de couvrir **lâ€™ensemble du cycle de vie de la donnÃ©e** :
- ingestion automatisÃ©e
- stockage cloud
- chargement analytique
- transformations SQL
- orchestration avec Airflow (Cloud Composer)
- analyse exploratoire
- visualisation
- prÃ©paration Ã  des usages Machine Learning

Ce projet peut servir de **rÃ©fÃ©rence reproductible** pour construire un pipeline ELT moderne sur GCP.

---

## ğŸ—ï¸ Architecture globale
```
Source (NYC Taxi Parquet)
|
v
Google Cloud Storage (GCS)
|
v
BigQuery (RAW)
|
v
BigQuery (TRANSFORMED)
|
v
Vues analytiques (SQL)
|
v
Notebooks Python BigQuery
|
v
(BigQuery ML - extension future)
```

---

## ğŸ§± Stack technologique
- **Google Cloud Storage (GCS)** : stockage des fichiers bruts
- **BigQuery** : entrepÃ´t de donnÃ©es analytique
- **Cloud Composer (Airflow 2)** : orchestration ELT
- **Python** : ingestion, automatisation
- **SQL BigQuery** : transformations, vues analytiques
- **BigQuery Notebooks (Python)** : analyse et visualisation

---

## 1ï¸âƒ£ Extraction des donnÃ©es (Extract)

### ğŸ¯ Source
Les donnÃ©es proviennent du site officiel NYC Taxi (format Parquet) :
- Yellow Taxi Trips (mensuels)

### ğŸ“„ Script principal
`download_taxi_data.py`

### ğŸ”§ Fonctionnement
- TÃ©lÃ©charge les fichiers Parquet depuis la source officielle
- VÃ©rifie si le fichier existe dÃ©jÃ  dans GCS (idempotence)
- Upload direct vers GCS
- GÃ©nÃ¨re des logs stockÃ©s dans GCS

### â–¶ï¸ ExÃ©cution (manuelle)
```bash
python download_taxi_data.py
```

## 2ï¸âƒ£ Stockage des donnÃ©es (GCS)

ğŸ“¦ Bucket
```
gs://<PROJECT_ID>-data-bucket/
```

ğŸ“‚ Structure
```
dataset/
 â””â”€â”€ trips/           # fichiers parquet taxi
from-git/
 â”œâ”€â”€ download_taxi_data.py
 â”œâ”€â”€ load_raw_trips_data.py
 â”œâ”€â”€ transform_trips_data.py
 â””â”€â”€ logs/
```

## 3ï¸âƒ£ Chargement BigQuery (Load)

ğŸ“„ Script
```
load_raw_trips_data.py
```
ğŸ¯ **Objectif**

Charger les fichiers Parquet depuis GCS vers BigQuery sans doublons.

ğŸ”§ **Fonctionnement**

- Liste les fichiers Parquet prÃ©sents dans GCS

- Compare avec les fichiers dÃ©jÃ  chargÃ©s (champ source_file)

- Charge chaque fichier dans une table temporaire

- InsÃ¨re les donnÃ©es dans la table finale RAW

- Supprime la table temporaire

ğŸ“Š Table cible
```
raw_yellowtrips.trips
```

## 4ï¸âƒ£ CrÃ©ation des datasets BigQuery

ğŸ“„ Script
```
create_datasets.py
```
ğŸ“ Datasets crÃ©Ã©s

- raw_yellowtrips â†’ donnÃ©es brutes

- transformed_data â†’ donnÃ©es nettoyÃ©es

- views_fordashboard â†’ vues analytiques

â–¶ï¸ ExÃ©cution
```
python create_datasets.py
```

## 5ï¸âƒ£ Transformation des donnÃ©es (Transform)

ğŸ“„ Script
```
transform_trips_data.py
```
ğŸ¯ **Objectif**

Nettoyer et filtrer les donnÃ©es pour un usage analytique.

ğŸ”§ RÃ¨gles appliquÃ©es

- passenger_count > 0

- trip_distance > 0

- total_amount > 0

- exclusion des paiements invalides

ğŸ“Š Table cible
```
transformed_data.cleaned_and_filtered
```

## 6ï¸âƒ£ Orchestration ELT avec Airflow (Cloud Composer)

ğŸ“„ DAG
```
elt_dag_pipeline.py
```
ğŸ§© **Ã‰tapes du pipeline**

* TÃ©lÃ©chargement des donnÃ©es â†’ GCS

* Chargement BigQuery RAW

* Transformation BigQuery

ğŸ” **ExÃ©cution**

- DÃ©ployÃ© dans le bucket dags/ de Cloud Composer

- DÃ©clenchÃ© manuellement ou via scheduling

- Gestion des retries et des logs

ğŸŸ¢ **RÃ©sultat**

Pipeline entiÃ¨rement automatisÃ© et stable dans Cloud Composer.

## 7ï¸âƒ£ CrÃ©ation de vues analytiques (SQL)

ğŸ¯ **Objectif**

PrÃ©parer des objets directement exploitables pour :

- dashboards

- notebooks

- analyses mÃ©tiers

ğŸ§  **Exemples de vues crÃ©Ã©es**

ğŸ“ˆ Demande dans le temps
```
views_fordashboard.demand_over_time
```
- analyse journaliÃ¨re, hebdomadaire, mensuelle

- saisonnalitÃ© et tendances

â° Heures de pointe par zone
```
views_fordashboard.peak_hours_by_zone
```
- jointure avec la table de rÃ©fÃ©rence des zones

- analyse horaire par borough et zone

## 8ï¸âƒ£ Analyse & visualisation avec BigQuery Notebooks

ğŸ““ **Contenu**

- Connexion native BigQuery â†’ DataFrame

- Analyse exploratoire

- Visualisations (tendances, distributions, comparaisons)

- PrÃ©paration de features analytiques

ğŸ¯ **Avantages**

- Pas de data export

- ScalabilitÃ© BigQuery

- Workflow Data Analyst / Data Scientist intÃ©grÃ©

## 9ï¸âƒ£ Ouverture vers le Machine Learning (BigQuery ML)

ğŸ”® **Perspectives**

Le projet est prÃªt pour :

- enrichissement externe (mÃ©tÃ©o, jours fÃ©riÃ©s)

- crÃ©ation de features SQL

- modÃ¨les BigQuery ML (rÃ©gression / classification)

**Exemples** :

- prÃ©diction du nombre de courses journaliÃ¨res

- prÃ©diction du montant total des trajets

# ğŸš€ Conclusion

Ce projet dÃ©montre la mise en place complÃ¨te dâ€™un pipeline ELT cloud-native, de lâ€™ingestion jusquâ€™Ã  lâ€™analyse avancÃ©e, en utilisant les outils standards de lâ€™Ã©cosystÃ¨me GCP.

Il constitue une base solide et rÃ©utilisable pour tout projet Data Engineering / Analytics sur Google Cloud.

# ğŸ‘¤ Auteur

Mamadou DIEDHIOU

Data Analyst / ChargÃ© d'Ã©tudes statistiques/ Data Engineer
